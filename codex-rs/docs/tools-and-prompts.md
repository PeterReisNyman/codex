# Codex Tools, Prompts, and System Messages

This document describes the tools Codex exposes to the model, what they accept/return, and how prompts and system messages are assembled each turn. Paths below refer to the Rust implementation.

- Tool definitions: `core/src/openai_tools.rs`, `core/src/tool_apply_patch.rs`, `core/src/plan_tool.rs`, `core/src/exec_command/*`
- Tool handling: `core/src/codex.rs` (see `handle_function_call`, `handle_custom_tool_call`)
- Prompt assembly: `core/prompt.md`, `core/src/client_common.rs`, `core/src/environment_context.rs`, `core/src/project_doc.rs`
- Streaming/client: `core/src/client.rs`, `core/src/chat_completions.rs`

## Prompts And System Messages

Each model turn is sent a Prompt that includes:

- Base instructions: The content of `core/prompt.md`. With the Responses API it is sent as the `instructions` field; with Chat Completions it is the first `system` message.
- User instructions: Optional free‑form instructions and concatenated project docs (`AGENTS.md` files) added as a user message wrapped in `<user_instructions> ... </user_instructions>` tags (see `Prompt::format_user_instructions_message`).
- Environment context: A user message containing an XML block `<environment_context>...</environment_context>` with `cwd`, approval policy, sandbox mode, network access, and shell. Built via `EnvironmentContext::new(...).into()`.
- Conversation history: All prior `ResponseItem`s (messages and tool calls with outputs) in order.
- Tools: A list of tools generated by `get_openai_tools(...)` based on model family and configuration.
- Reasoning and storage controls: Per‑model reasoning settings and `store` decide whether encrypted reasoning content is requested and whether the upstream server stores responses.

Notes:
- The UI stream (assistant deltas, reasoning deltas, exec output deltas) is untruncated. The model‑facing echo of exec output is summarized to keep within context limits.
- On Chat Completions, tool calls are expressed as `assistant` messages with `tool_calls`; on Responses API, they are structured `output_item` entries.

## Tool Catalog

Below are the tools as seen by the model, how to call them, and how Codex responds.

### Shell Execution

Codex exposes one of the following based on configuration and model family:

- `shell` (function tool): Default shell executor.
- `shell` (function tool with escalation fields): When approval policy is `on-request` and streamable shell is disabled, the schema includes `with_escalated_permissions` (bool) and `justification` (string) to request unsandboxed retries.
- `local_shell` (built‑in tool): For model families that natively support a local shell call.
- Streamable shell (experimental): `exec_command` + `write_stdin` pair for interactive sessions.

Inputs (function `shell`):

```json
{
  "command": ["git", "status"],
  "workdir": "/path/optional",
  "timeout_ms": 10000,
  "with_escalated_permissions": false,
  "justification": "why escalation is needed"
}
```

Outputs to the model (all variants):

- Function result is returned as `FunctionCallOutput` with a string `output.content` and `success` flag (informational). The string contains head+tail truncated stdout+stderr plus metadata; deltas are still streamed live to the UI.
- Events to UI: `ExecCommandBegin`, zero or more `ExecCommandOutputDelta`, and `ExecCommandEnd` (includes `exit_code`, duration, etc.). If the command mapped to `apply_patch`, `PatchApplyBegin`/`PatchApplyEnd` events are emitted instead.

Safety and sandboxing:
- Codex evaluates safety via `assess_command_safety` against approval/sandbox policies. It may auto‑approve (run in sandbox or unsandboxed), ask the user (`ExecApprovalRequest`), or reject with a structured failure payload.
- On sandbox failures (`Denied` or `Timeout`) and policies like `on-failure`, Codex can ask to retry without sandbox; if approved, it escalates and re‑runs unsandboxed.

### Apply Patch

Codex provides an `apply_patch` tool in two forms:

- Freeform custom tool (recommended for GPT‑5): Grammar‑based payload, see `create_apply_patch_freeform_tool()`.
- JSON function tool (for OSS models): `{"input": "<entire apply_patch block>"}` (see `create_apply_patch_json_tool()`).

The patch language is a constrained diff envelope:

```
*** Begin Patch
[ one or more file sections ]
*** End Patch
```

Operations: `*** Add File:`, `*** Delete File:`, `*** Update File:` with optional `*** Move to:` and `@@` hunks. Lines start with `+`, `-`, or space. See `core/src/tool_apply_patch.rs` for the full grammar and examples.

Behavior:
- Codex verifies/normalizes patches. If the patch is ambiguous/incorrect, it returns a failure payload so the model can re‑sample.
- When a patch is valid, Codex requests approval if needed, applies changes atomically, and emits `PatchApplyBegin`/`PatchApplyEnd` with a unified diff. The model receives a `FunctionCallOutput` (string summary; `success` true/false).
- If the patch resolves to an internal CLI invocation (`codex --apply_patch …`) and user explicitly approved, Codex runs it unsandboxed.

### Plan Tool (`update_plan`)

Purpose: give the model a structured way to surface a plan that front‑ends can render.

Schema:

```json
{
  "explanation": "optional context",
  "plan": [
    {"step": "Add CLI entry", "status": "pending"},
    {"step": "Write tests", "status": "in_progress"}
  ]
}
```

Behavior:
- On success, Codex emits a `PlanUpdate` event with the parsed args and returns `FunctionCallOutput` with content "Plan updated" and `success: true`.
- If JSON parsing fails, Codex returns `FunctionCallOutput` with an error string (`success: false`) so the model can correct the call.

### Web Search (preview)

- Tool name: `web_search` (serialized as `web_search_preview`).
- Emitted by upstream when the model triggers search. Codex forwards `WebSearchBegin` and `WebSearchEnd` events with the query. There is no local execution; the model may receive a corresponding `web_search_call` item on the stream.

### View Image (`view_image`)

Purpose: let the model attach a local image path to the conversation context for the current turn.

Input:

```json
{ "path": "relative/or/absolute/path/to/image.png" }
```

Behavior:
- Codex resolves to an absolute path (relative to the session cwd) and injects it as an image in the next input message as a `data:` URL.
- Returns `FunctionCallOutput` with a short status message.

### Streamable Shell (experimental)

Two function tools are exposed when `use_experimental_streamable_shell_tool = true`:

- `exec_command`: starts an interactive PTY shell and returns a running session (or an exit code) along with a snapshot of stdout/stderr collected within `yield_time_ms`. Parameters include `cmd`, `yield_time_ms`, `max_output_tokens`, `shell`, and `login`.
- `write_stdin`: writes characters to the PTY of a running `exec_command` session, then returns stdout/stderr collected within `yield_time_ms`.

Outputs:
- Both return `FunctionCallOutput` with a textual summary. For ongoing sessions, the text includes `Process running with session ID N`; for exits it includes `Process exited with code X` and wall time.

### MCP Tools

If MCP servers are configured, their tools are converted into OpenAI function tools:
- Deterministic ordering by fully qualified name (e.g., `server/tool`).
- Calls are handled via `handle_mcp_tool_call`, which emits `McpToolCallBegin`/`McpToolCallEnd` with duration and result. The model receives a `FunctionCallOutput` containing the (JSON‑serialized) `CallToolResult` or an error string.

## What Tools Return To The Model

All tool calls ultimately produce a `ResponseInputItem` that is fed into the next turn:

- `FunctionCallOutput { call_id, output }` → recorded to history; `output` is serialized as a plain string even on failure (matches upstream CLI). The optional `success` flag is for local bookkeeping.
- `CustomToolCallOutput { call_id, output }` → for custom/freeform tools.
- `McpToolCallOutput { call_id, result }` → recorded as a `FunctionCallOutput` for history with `success` derived from `result.is_ok()`.

Event stream sent to UI (subset):
- `AgentMessageDelta`, `AgentMessage`, `AgentReasoningDelta`, optional raw `AgentReasoningRawContentDelta`
- `ExecApprovalRequest`, `ApplyPatchApprovalRequest`, `BackgroundEvent`, `StreamError`
- `ExecCommandBegin`/`End`, `PatchApplyBegin`/`End`, `McpToolCallBegin`/`End`, `WebSearchBegin`/`End`
- `TurnDiff` (unified diff after file changes), `TokenCount`, `TaskComplete`

## How Tools Are Picked Per Session

`get_openai_tools(...)` selects tools based on:
- Model family capabilities (e.g., `local_shell` vs `shell`, apply‑patch tool form, reasoning support)
- Approval/sandbox policy (affects `shell` schema and escalation parameters)
- Config flags: `include_plan_tool`, `include_apply_patch_tool`, `tools_web_search_request`, `use_experimental_streamable_shell_tool`, `include_view_image_tool`
- MCP tools discovered from configured servers

## System Message: `core/prompt.md`

This file encodes Codex’s persona, response style, planning rules, tool preambles, and formatting conventions. It instructs the agent to:
- Be concise, direct, and friendly; provide actionable guidance
- Send short preambles before running tools and group related actions
- Use the plan tool to track multi‑step work
- Stream progress updates succinctly
- Respect formatting conventions (headers, bullets, monospace) when presenting results

The full text is included as `instructions` (Responses API) or a `system` message (Chat Completions API) on every turn.

## Environment Context And Project Docs

- Environment context is serialized as a tagged user message with machine‑readable fields (cwd, sandbox/approval, network access, shell). The model can parse this block to adapt behavior.
- Project docs discovery: concatenates all `AGENTS.md` files from repo root down to the session cwd (bounded by `project_doc_max_bytes`) and adds them to the initial user instructions.

## Tips For Tool Authors

- Keep tool schemas strict but minimal; add descriptions for each field
- Prefer arrays of strings for shell commands (`["git", "status"]`), not a single string
- When adding new tools, ensure `get_openai_tools(...)` returns them conditionally and that `handle_function_call` matches the tool names exactly
- For long outputs, rely on Codex’s built‑in head+tail summarization for model‑facing content while streaming full content to the UI

